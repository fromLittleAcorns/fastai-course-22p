# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/10_Activations.ipynb.

# %% ../nbs/10_Activations.ipynb 2
from __future__ import annotations
import random,math,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt
import fastcore.all as fc
from pathlib import Path
from operator import attrgetter,itemgetter
from functools import partial

from torch import tensor,nn,optim
import torch.nn.functional as F
import torchvision.transforms.functional as TF
from datasets import load_dataset

from .datasets import *
from .learner import *

# %% auto 0
__all__ = ['set_seed', 'Hook', 'Hooks', 'HooksCallback', 'append_stats', 'get_hist', 'get_min', 'ActivationStatsCB']

# %% ../nbs/10_Activations.ipynb 4
def set_seed(seed, deterministic=False):
    torch.use_deterministic_algorithms(deterministic)
    torch.manual_seed(seed)
    random.seed(seed)
    np.random.seed(seed)

# %% ../nbs/10_Activations.ipynb 30
class Hook():
    def __init__(self, m, func): 
        self.hook = m.register_forward_hook(partial(func, self))
    def remove(self):
        self.hook.remove()
    def __del__(self):
        self.remove()

# %% ../nbs/10_Activations.ipynb 44
class Hooks(list):
    """ Class to act as a container and context manager for a set of hooks and to ensure that they are 
    all removed at the end.  For the context manager the very least that is needed is an __enter__ and 
    and __exit__.
    
    The __del__ method is called to delete the class should that be required
    
    """
    def __init__(self, mdl, func):
        # Initialize a hook for each layer and assign to a list
        super().__init__([Hook(l, func) for l in mdl])
    def __enter__(self, *args): return self
    def __exit__(self, *args): self.remove()
    def __del__(self):
        # triggered to delete the class.  This calls the remove method to remove all of the hooks
        self.remove()
    def __delitem__(self, i):
        # delete a specific hook from the model
        self[i].remove()
        # remove the hook from the list
        super().__delitem__(i)
    def remove(self): 
        for h in self: h.remove()
        

# %% ../nbs/10_Activations.ipynb 49
class HooksCallback(Callback):
    def __init__(self, hookfunc, module_filter=fc.noop):
        fc.store_attr()
        super().__init__()
    
    def before_fit(self, learn): 
        # get list of filtered layers
        filt_layers = fc.filter_ex(learn.model.modules(), self.module_filter)
        # create hooks
        self.hooks = Hooks(filt_layers, partial(self._hookfunc, learn))
    
    def _hookfunc(self, learn, *args, **kwargs):
        if learn.training: self.hookfunc(*args, **kwargs)
    
    def after_fit(self, learn): self.hooks.remove()
    
    def __iter__(self): return iter(self.hooks)
    def __len__(self): return len(self.hooks)
    

# %% ../nbs/10_Activations.ipynb 57
def append_stats(hook, mod, inp, outp):
    if not hasattr(hook,'stats'): hook.stats = ([],[],[])
    acts = to_cpu(outp)
    hook.stats[0].append(acts.mean())
    hook.stats[1].append(acts.std())
    hook.stats[2].append(acts.abs().histc(40,0,10))

# %% ../nbs/10_Activations.ipynb 59
# Thanks to @ste for initial version of histgram plotting code
def get_hist(h): return torch.stack(h.stats[2]).t().float().log1p()

# %% ../nbs/10_Activations.ipynb 66
def get_min(h):
    """ Calculate the proportion of activations in the smallest bin
    """
    h_arr = torch.stack(h.stats[2]).t().float()
    return h_arr[0] / h_arr.sum(0)

# %% ../nbs/10_Activations.ipynb 71
class ActivationStatsCB(HooksCallback):
    """ Note that this builds upon the earlier work.  I have deviated from the course by passing in the 
    hookfunc since I think this gived greater flexibility moving forwards, although so many things are 
    now linked to the structure of the appstats function that it might be better to simply integrate that
    into this class
    """
    def __init__(self, hookfunc, module_filter=fc.noop):
        super().__init__(hookfunc, module_filter)
        
    def color_dim(self, figsize=(11,5)):
        fig,axes = get_grid(len(self), figsize=figsize)
        for ax,h in zip(axes.flat, self):
            show_image(get_hist(h), ax, origin='lower')
    
    def dead_chart(self, figsize=(11,5)):
        fig,axes = get_grid(len(self), figsize=(11,5))
        for ax,h in zip(axes.flatten(), self):
            ax.plot(get_min(h))
            ax.set_ylim(0,1)

    def plot_stats(self, figsize=(10,4)):
        fig,axs = plt.subplots(1,2, figsize=figsize)
        for h in self:
            for i in 0,1: 
                axs[i].plot(h.stats[i])
        axs[0].set_title('Means')
        axs[1].set_title('Stdevs')
        plt.legend(fc.L.range(self))
